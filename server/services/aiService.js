const OpenAI = require('openai');
const { aiConfig, validateConfig } = require('../config/aiConfig');
const {
  withRetry,
  buildRequestParams,
  normalizeResponse,
  validateResponse
} = require('../utils/aiHelpers');
const logger = require('../utils/logger');

class AIService {
  constructor() {
    this.providers = new Map();
    this.initializeProviders();
    
    // éªŒè¯AIé…ç½®
    try {
      validateConfig();
    } catch (error) {
      console.warn('AIé…ç½®éªŒè¯è­¦å‘Š:', error.message);
    }
  }

  initializeProviders() {
    // Initialize OpenAI-compatible providers
    if (aiConfig.openai.apiKey) {
      this.providers.set('openai', {
        client: new OpenAI({
          apiKey: aiConfig.openai.apiKey,
          baseURL: aiConfig.openai.baseURL,
          timeout: aiConfig.openai.timeout
        }),
        type: 'openai',
        models: {
          chat: aiConfig.openai.model,
          embedding: aiConfig.openai.embeddingModel
        }
      });
    }

    // Initialize Claude provider
    if (aiConfig.claude.apiKey) {
      this.providers.set('claude', {
        client: null, // Will be initialized when needed
        config: {
          apiKey: aiConfig.claude.apiKey,
          baseURL: aiConfig.claude.baseURL,
          timeout: aiConfig.claude.timeout
        },
        type: 'claude',
        models: {
          chat: aiConfig.claude.model
        }
      });
    }

    // Support for custom OpenAI-compatible providers
    if (aiConfig.custom.name && aiConfig.custom.apiKey && aiConfig.custom.baseURL) {
      this.providers.set(aiConfig.custom.name, {
        client: new OpenAI({
          apiKey: aiConfig.custom.apiKey,
          baseURL: aiConfig.custom.baseURL
        }),
        type: 'openai',
        models: {
          chat: aiConfig.custom.model || 'gpt-3.5-turbo'
        }
      });
    }
  }

  getDefaultProvider() {
    const preferredProvider = aiConfig.global.defaultProvider;
    return this.providers.get(preferredProvider) || this.providers.values().next().value;
  }

  async chat(messages, options = {}) {
    const provider = options.provider ? this.providers.get(options.provider) : this.getDefaultProvider();
    
    if (!provider) {
      throw new Error('No AI provider available');
    }

    if (provider.type === 'openai') {
      return await this.openaiChat(provider, messages, options);
    } else if (provider.type === 'claude') {
      return await this.claudeChat(provider, messages, options);
    }
    
    throw new Error(`Unsupported provider type: ${provider.type}`);
  }

  async chatStream(messages, options = {}) {
    const provider = options.provider ? this.providers.get(options.provider) : this.getDefaultProvider();
    
    if (!provider) {
      throw new Error('No AI provider available');
    }

    if (provider.type === 'openai') {
      return await this.openaiChatStream(provider, messages, options);
    } else if (provider.type === 'claude') {
      return await this.claudeChatStream(provider, messages, options);
    }
    
    throw new Error(`Unsupported provider type: ${provider.type}`);
  }

  async openaiChat(provider, messages, options) {
    const taskType = options.taskType || 'default';
    const startTime = Date.now();

    const requestFn = async () => {
      const params = buildRequestParams('openai', taskType, {
        model: options.model || provider.models.chat,
        temperature: options.temperature,
        maxTokens: options.maxTokens,
        ...options.additionalParams
      });

      const requestData = {
        messages: messages,
        ...params
      };

      const response = await provider.client.chat.completions.create(requestData);

      // Log successful API call
      const duration = Date.now() - startTime;
      logger.logApiCall('openai', '/chat/completions', requestData, response, duration);

      return normalizeResponse(response, 'openai');
    };

    try {
      const result = await withRetry(requestFn, 'openai');

      return {
        content: result.content,
        usage: result.usage,
        provider: 'openai',
        model: result.model,
        finishReason: result.finishReason
      };
    } catch (error) {
      // Log failed API call
      const duration = Date.now() - startTime;
      const requestData = {
        model: options.model || provider.models.chat,
        messages: messages,
        temperature: options.temperature,
        max_tokens: options.maxTokens
      };
      logger.logApiCall('openai', '/chat/completions', requestData, null, duration, error);

      logger.error('OpenAI API Error:', {
        error: error.message,
        stack: error.stack,
        model: options.model || provider.models.chat,
        messageCount: messages.length
      });
      throw new Error(`OpenAI API Error: ${error.message}`);
    }
  }

  async claudeChat(provider, messages, options) {
    const startTime = Date.now();

    try {
      // Convert OpenAI format messages to Claude format
      const systemMessage = messages.find(m => m.role === 'system')?.content || '';
      const userMessages = messages.filter(m => m.role !== 'system');

      const requestData = {
        model: options.model || provider.models.chat,
        system: systemMessage,
        messages: userMessages,
        max_tokens: options.maxTokens || 2000,
        temperature: options.temperature || 0.7,
        ...options.additionalParams
      };

      const response = await fetch(`${provider.config.baseURL}/v1/messages`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'x-api-key': provider.config.apiKey,
          'anthropic-version': '2023-06-01'
        },
        body: JSON.stringify(requestData)
      });

      if (!response.ok) {
        const errorText = await response.text();
        const duration = Date.now() - startTime;
        const error = new Error(`Claude API Error: ${response.status} ${response.statusText} - ${errorText}`);
        logger.logApiCall('claude', '/v1/messages', requestData, null, duration, error);
        throw error;
      }

      const data = await response.json();

      // Log successful API call
      const duration = Date.now() - startTime;
      logger.logApiCall('claude', '/v1/messages', requestData, data, duration);

      return {
        content: data.content[0].text,
        usage: data.usage,
        provider: 'claude'
      };
    } catch (error) {
      const duration = Date.now() - startTime;
      logger.error('Claude API Error:', {
        error: error.message,
        stack: error.stack,
        model: options.model || provider.models.chat,
        messageCount: messages.length
      });
      throw new Error(`Claude API Error: ${error.message}`);
    }
  }

  async openaiChatStream(provider, messages, options) {
    const taskType = options.taskType || 'default';

    const params = buildRequestParams('openai', taskType, {
      model: options.model || provider.models.chat,
      temperature: options.temperature,
      maxTokens: options.maxTokens,
      stream: true, // Enable streaming
      ...options.additionalParams
    });

    const requestData = {
      messages: messages,
      ...params
    };

    try {
      const stream = await provider.client.chat.completions.create(requestData);
      return stream;
    } catch (error) {
      logger.error('OpenAI Stream Error:', {
        error: error.message,
        stack: error.stack,
        model: options.model || provider.models.chat,
        messageCount: messages.length
      });
      throw new Error(`OpenAI Stream Error: ${error.message}`);
    }
  }

  async claudeChatStream(provider, messages, options) {
    const startTime = Date.now();

    try {
      // Convert OpenAI format messages to Claude format
      const systemMessage = messages.find(m => m.role === 'system')?.content || '';
      const userMessages = messages.filter(m => m.role !== 'system');

      const requestData = {
        model: options.model || provider.models.chat,
        system: systemMessage,
        messages: userMessages,
        max_tokens: options.maxTokens || 2000,
        temperature: options.temperature || 0.7,
        stream: true, // Enable streaming
        ...options.additionalParams
      };

      const response = await fetch(`${provider.config.baseURL}/v1/messages`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'x-api-key': provider.config.apiKey,
          'anthropic-version': '2023-06-01'
        },
        body: JSON.stringify(requestData)
      });

      if (!response.ok) {
        const errorText = await response.text();
        const error = new Error(`Claude Stream Error: ${response.status} ${response.statusText} - ${errorText}`);
        throw error;
      }

      return response.body;
    } catch (error) {
      logger.error('Claude Stream Error:', {
        error: error.message,
        stack: error.stack,
        model: options.model || provider.models.chat,
        messageCount: messages.length
      });
      throw new Error(`Claude Stream Error: ${error.message}`);
    }
  }

  // Novel-specific AI methods
  async generateResponse(novelContext, userMessage, type = 'general', options = {}) {
    const systemPrompt = this.buildSystemPrompt(novelContext, type);
    
    const messages = [
      { role: 'system', content: systemPrompt },
      { role: 'user', content: userMessage }
    ];

    const response = await this.chat(messages, {
      temperature: options.temperature || (type === 'creative' ? 0.9 : 0.7),
      provider: options.provider,
      model: options.model
    });

    return this.parseResponse(response.content, type);
  }

  async generateResponseStream(novelContext, userMessage, type = 'general', options = {}) {
    const systemPrompt = this.buildSystemPrompt(novelContext, type);
    
    const messages = [
      { role: 'system', content: systemPrompt },
      { role: 'user', content: userMessage }
    ];

    const stream = await this.chatStream(messages, {
      temperature: options.temperature || (type === 'creative' ? 0.9 : 0.7),
      provider: options.provider,
      model: options.model
    });

    return stream;
  }

  buildSystemPrompt(novelContext, type) {
    let basePrompt = 'ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å°è¯´åˆ›ä½œåŠ©æ‰‹ã€‚';
    
    if (novelContext) {
      basePrompt += `\nå½“å‰å°è¯´ä¿¡æ¯ï¼š\næ ‡é¢˜ï¼š${novelContext.title}\næè¿°ï¼š${novelContext.description}\nç±»å‹ï¼š${novelContext.genre}`;
      
      if (novelContext.characters?.length > 0) {
        basePrompt += `\nä¸»è¦è§’è‰²ï¼š\n${novelContext.characters.map(c => `- ${c.name}: ${c.description}`).join('\n')}`;
      }
      
      if (novelContext.settings?.length > 0) {
        basePrompt += `\nä¸–ç•Œè®¾å®šï¼š\n${novelContext.settings.map(s => `- ${s.name}: ${s.description}`).join('\n')}`;
      }
      
      if (novelContext.aiSettings) {
        basePrompt += `\nå†…å®¹é™åˆ¶ï¼šåˆ†çº§${novelContext.aiSettings.rating}`;
      }
    }

    switch (type) {
      case 'creative':
        basePrompt += '\nè¯·ä»¥åˆ›æ„å’Œæƒ³è±¡åŠ›ä¸ºé‡ç‚¹å›ç­”ã€‚';
        break;
      case 'analytical':
        basePrompt += '\nè¯·ä»¥é€»è¾‘åˆ†æå’Œç»“æ„åŒ–æ€è€ƒä¸ºé‡ç‚¹å›ç­”ã€‚';
        break;
      case 'consistency':
        basePrompt += '\nè¯·é‡ç‚¹å…³æ³¨å†…å®¹çš„ä¸€è‡´æ€§å’Œè¿è´¯æ€§ã€‚';
        break;
      default:
        basePrompt += '\nè¯·æä¾›æœ‰å¸®åŠ©çš„å»ºè®®å’Œåˆ†æã€‚';
    }

    return basePrompt;
  }

  parseResponse(content, type, novelContext = null) {
    // Enhanced response structure
    const result = {
      message: content,
      suggestions: [],
      questions: [],
      actions: [],
      metadata: {
        type,
        timestamp: new Date().toISOString(),
        wordCount: content.length,
        hasStructuredContent: false
      }
    };

    // Extract structured information with multiple patterns
    const suggestionMarkers = ['å»ºè®®ï¼š', 'å»ºè®®:', 'ğŸ’¡', 'âœ…', 'æ¨èï¼š', 'æ¨è:'];
    const questionMarkers = ['é—®é¢˜ï¼š', 'é—®é¢˜:', 'â“', 'ğŸ¤”', 'éœ€è¦è€ƒè™‘ï¼š', 'éœ€è¦è€ƒè™‘:'];
    const actionMarkers = ['ä¸‹ä¸€æ­¥ï¼š', 'ä¸‹ä¸€æ­¥:', 'ğŸ¯', 'âš¡', 'è¡ŒåŠ¨å»ºè®®ï¼š', 'è¡ŒåŠ¨å»ºè®®:'];

    result.suggestions = this.extractBulletPoints(content, suggestionMarkers);
    result.questions = this.extractBulletPoints(content, questionMarkers);
    result.actions = this.extractBulletPoints(content, actionMarkers);

    // Detect if response has structured content
    result.metadata.hasStructuredContent =
      result.suggestions.length > 0 ||
      result.questions.length > 0 ||
      result.actions.length > 0 ||
      content.includes('**') ||
      content.includes('â€¢') ||
      content.includes('1.') ||
      content.includes('##');

    // Add type-specific parsing
    switch (type) {
      case 'consistency':
        result.issues = this.extractConsistencyIssues(content);
        break;
      case 'character':
        result.characterTraits = this.extractCharacterTraits(content);
        break;
      case 'worldbuilding':
        result.worldElements = this.extractWorldElements(content);
        break;
      case 'outline':
        result.plotPoints = this.extractPlotPoints(content);
        break;
    }

    // Generate follow-up suggestions based on content
    result.followUps = this.generateFollowUps(content, type, novelContext);

    return result;
  }

  extractConsistencyIssues(content) {
    const issues = [];
    const issuePatterns = [
      /âŒ\s*(.+)/g,
      /âš ï¸\s*(.+)/g,
      /ğŸ”´\s*(.+)/g,
      /é—®é¢˜[ï¼š:]\s*(.+)/g
    ];

    for (const pattern of issuePatterns) {
      let match;
      while ((match = pattern.exec(content)) !== null) {
        issues.push(match[1].trim());
      }
    }

    return issues;
  }

  extractCharacterTraits(content) {
    const traits = [];
    const traitPatterns = [
      /æ€§æ ¼[ï¼š:]\s*(.+)/g,
      /ç‰¹å¾[ï¼š:]\s*(.+)/g,
      /ç‰¹ç‚¹[ï¼š:]\s*(.+)/g
    ];

    for (const pattern of traitPatterns) {
      let match;
      while ((match = pattern.exec(content)) !== null) {
        traits.push(match[1].trim());
      }
    }

    return traits;
  }

  extractWorldElements(content) {
    const elements = [];
    const elementPatterns = [
      /ğŸ›ï¸\s*(.+)/g,
      /ğŸŒ\s*(.+)/g,
      /è®¾å®š[ï¼š:]\s*(.+)/g
    ];

    for (const pattern of elementPatterns) {
      let match;
      while ((match = pattern.exec(content)) !== null) {
        elements.push(match[1].trim());
      }
    }

    return elements;
  }

  extractPlotPoints(content) {
    const points = [];
    const pointPatterns = [
      /ğŸ“Š\s*(.+)/g,
      /æƒ…èŠ‚[ï¼š:]\s*(.+)/g,
      /ç¬¬\d+ç« [ï¼š:]\s*(.+)/g
    ];

    for (const pattern of pointPatterns) {
      let match;
      while ((match = pattern.exec(content)) !== null) {
        points.push(match[1].trim());
      }
    }

    return points;
  }

  generateFollowUps(content, type, novelContext) {
    const followUps = [];

    // Generate context-aware follow-up questions
    if (type === 'character' && content.includes('æ€§æ ¼')) {
      followUps.push('è¦ä¸è¦ç»§ç»­å®Œå–„è¿™ä¸ªè§’è‰²çš„èƒŒæ™¯æ•…äº‹ï¼Ÿ');
      followUps.push('éœ€è¦ä¸ºè¿™ä¸ªè§’è‰²è®¾è®¡ä¸€äº›å…·ä½“çš„å¯¹è¯é£æ ¼å—ï¼Ÿ');
    }

    if (type === 'worldbuilding' && content.includes('è®¾å®š')) {
      followUps.push('éœ€è¦è¿›ä¸€æ­¥æ‰©å±•è¿™ä¸ªä¸–ç•Œçš„å†å²èƒŒæ™¯å—ï¼Ÿ');
      followUps.push('è¦ä¸ºè¿™ä¸ªè®¾å®šæ·»åŠ ä¸€äº›å…·ä½“çš„è§„åˆ™é™åˆ¶å—ï¼Ÿ');
    }

    if (type === 'consistency' && content.includes('é—®é¢˜')) {
      followUps.push('è¦æˆ‘å¸®ä½ åˆ¶å®šä¿®å¤è¿™äº›é—®é¢˜çš„å…·ä½“æ–¹æ¡ˆå—ï¼Ÿ');
      followUps.push('éœ€è¦æ£€æŸ¥å…¶ä»–ç« èŠ‚æ˜¯å¦æœ‰ç±»ä¼¼é—®é¢˜å—ï¼Ÿ');
    }

    return followUps.slice(0, 3); // Limit to 3 follow-ups
  }

  extractBulletPoints(text, markers) {
    const points = [];
    const uniquePoints = new Set();

    for (const marker of markers) {
      const regex = new RegExp(`${marker.replace(/[.*+?^${}()|[\]\\]/g, '\\$&')}([\\s\\S]*?)(?=\\n\\n|\\n[^\\nâ€¢\\-\\d]|$)`, 'g');
      let match;

      while ((match = regex.exec(text)) !== null) {
        const section = match[1];
        const lines = section.split('\n');

        for (const line of lines) {
          const trimmed = line.trim();
          const bulletPatterns = [
            /^[-â€¢âœ“âœ…]\s*(.+)$/,
            /^\d+\.\s*(.+)$/,
            /^[a-zA-Z]\)\s*(.+)$/,
            /^[\u4e00-\u9fff]ã€\s*(.+)$/
          ];

          for (const pattern of bulletPatterns) {
            const bulletMatch = trimmed.match(pattern);
            if (bulletMatch && bulletMatch[1]) {
              const point = bulletMatch[1].trim();
              if (point.length > 5 && !uniquePoints.has(point)) {
                uniquePoints.add(point);
                points.push(point);
              }
              break;
            }
          }
        }
      }
    }

    return points.slice(0, 10); // Limit to avoid too many points
  }

  async checkConsistency(novelData, scope = 'full') {
    const startTime = Date.now();

    const systemPrompt = `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å°è¯´ä¸€è‡´æ€§æ£€æŸ¥åŠ©æ‰‹ã€‚è¯·ä»”ç»†æ£€æŸ¥ä»¥ä¸‹å†…å®¹ä¸­çš„ä¸€è‡´æ€§é—®é¢˜ï¼š

æ£€æŸ¥é‡ç‚¹ï¼š
1. è§’è‰²æ€§æ ¼å’Œè¡Œä¸ºçš„ä¸€è‡´æ€§
2. ä¸–ç•Œè®¾å®šçš„é€»è¾‘ä¸€è‡´æ€§
3. æ—¶é—´çº¿çš„åˆç†æ€§
4. æƒ…èŠ‚å‘å±•çš„è¿è´¯æ€§

è¯·ä»¥JSONæ ¼å¼è¿”å›æ£€æŸ¥ç»“æœï¼ŒåŒ…å«ï¼š
- issues: é—®é¢˜åˆ—è¡¨ï¼Œæ¯ä¸ªé—®é¢˜åŒ…å« type(ç±»å‹), severity(ä¸¥é‡ç¨‹åº¦), issue(é—®é¢˜æè¿°), suggestion(ä¿®æ”¹å»ºè®®)
- summary: é—®é¢˜ç»Ÿè®¡æ‘˜è¦`;

    const messages = [
      { role: 'system', content: systemPrompt },
      { role: 'user', content: this.formatNovelDataForConsistency(novelData) }
    ];

    try {
      const response = await this.chat(messages, {
        temperature: 0.3, // Lower temperature for consistency checking
        taskType: 'consistency'
      });

      let result;
      try {
        // Try to parse as JSON first
        result = JSON.parse(response.content);
      } catch (parseError) {
        // If JSON parsing fails, try to extract structured info from text
        result = this.parseConsistencyFromText(response.content);
      }

      // Ensure result has required structure
      if (!result.issues) result.issues = [];
      if (!result.summary) {
        const issues = result.issues;
        result.summary = {
          total: issues.length,
          high: issues.filter(i => i.severity === 'high').length,
          medium: issues.filter(i => i.severity === 'medium').length,
          low: issues.filter(i => i.severity === 'low').length
        };
      }

      // Log consistency check
      const duration = Date.now() - startTime;
      logger.logConsistencyCheck(novelData.id, scope, result.issues || [], duration);

      return result;
    } catch (error) {
      const duration = Date.now() - startTime;
      logger.error('Consistency check failed:', {
        novelId: novelData.id,
        scope,
        error: error.message,
        duration: `${duration}ms`
      });

      // Enhanced fallback response
      return {
        issues: [{
          type: 'system',
          severity: 'low',
          issue: 'AIä¸€è‡´æ€§æ£€æŸ¥æœåŠ¡æš‚æ—¶ä¸å¯ç”¨',
          suggestion: 'è¯·ç¨åé‡è¯•ï¼Œæˆ–æ‰‹åŠ¨æ£€æŸ¥å†…å®¹ä¸€è‡´æ€§ã€‚æ‚¨å¯ä»¥é‡ç‚¹å…³æ³¨è§’è‰²è¡Œä¸ºã€æ—¶é—´çº¿å’Œä¸–ç•Œè®¾å®šçš„è¿è´¯æ€§ã€‚'
        }],
        summary: { total: 1, high: 0, medium: 0, low: 1 }
      };
    }
  }

  parseConsistencyFromText(content) {
    const issues = [];
    const lines = content.split('\n');

    for (const line of lines) {
      const trimmed = line.trim();

      // Look for issue indicators
      if (trimmed.includes('âŒ') || trimmed.includes('é—®é¢˜') || trimmed.includes('çŸ›ç›¾')) {
        issues.push({
          type: 'consistency',
          severity: 'medium',
          issue: trimmed.replace(/[âŒâš ï¸ğŸ”´]/g, '').trim(),
          suggestion: 'è¯·æ£€æŸ¥å¹¶ä¿®æ­£æ­¤ä¸€è‡´æ€§é—®é¢˜'
        });
      } else if (trimmed.includes('âš ï¸') || trimmed.includes('æ³¨æ„')) {
        issues.push({
          type: 'warning',
          severity: 'low',
          issue: trimmed.replace(/[âŒâš ï¸ğŸ”´]/g, '').trim(),
          suggestion: 'å»ºè®®è¿›ä¸€æ­¥ç¡®è®¤æ­¤å¤„å†…å®¹'
        });
      }
    }

    return {
      issues,
      summary: {
        total: issues.length,
        high: 0,
        medium: issues.filter(i => i.severity === 'medium').length,
        low: issues.filter(i => i.severity === 'low').length
      },
      rawContent: content
    };
  }

  formatNovelDataForConsistency(novelData) {
    let formatted = `å°è¯´ï¼š${novelData.title}\n`;
    
    if (novelData.characters?.length > 0) {
      formatted += '\nè§’è‰²ä¿¡æ¯ï¼š\n';
      novelData.characters.forEach(char => {
        formatted += `${char.name}: ${char.description}\næ€§æ ¼ï¼š${char.personality || 'æœªè®¾å®š'}\nèƒŒæ™¯ï¼š${char.background || 'æœªè®¾å®š'}\n\n`;
      });
    }

    if (novelData.chapters?.length > 0) {
      formatted += '\nç« èŠ‚å†…å®¹ï¼š\n';
      novelData.chapters.forEach(chapter => {
        formatted += `ç¬¬${chapter.chapterNumber}ç«  - ${chapter.title}\n`;
        if (chapter.outline) formatted += `å¤§çº²ï¼š${chapter.outline}\n`;
        if (chapter.content) formatted += `å†…å®¹ï¼š${chapter.content.substring(0, 500)}...\n`;
        formatted += '\n';
      });
    }

    return formatted.substring(0, 8000); // Limit context size to avoid token limits
  }

  // New method for enhanced conversation support
  async generateConversationalResponse(novelContext, userMessage, conversationHistory = [], options = {}) {
    const systemPrompt = this.buildConversationalPrompt(novelContext, options.mode);

    const messages = [{ role: 'system', content: systemPrompt }];

    // Add relevant conversation history
    if (conversationHistory.length > 0) {
      const recentHistory = conversationHistory.slice(-8); // Last 8 messages
      messages.push(...recentHistory.map(msg => ({
        role: msg.role,
        content: msg.content
      })));
    }

    messages.push({ role: 'user', content: userMessage });

    const response = await this.chat(messages, {
      temperature: 0.8, // Slightly higher for natural conversation
      provider: options.provider,
      model: options.model
    });

    return {
      content: response.content,
      suggestions: this.extractBulletPoints(response.content, ['å»ºè®®ï¼š', 'å»ºè®®:', 'ğŸ’¡']),
      followUps: this.generateFollowUps(response.content, 'general', novelContext),
      metadata: {
        provider: response.provider,
        model: response.model,
        timestamp: new Date().toISOString()
      }
    };
  }

  buildConversationalPrompt(novelContext, mode = 'chat') {
    let prompt = 'ä½ æ˜¯ä¸€ä¸ªç»éªŒä¸°å¯Œçš„å°è¯´åˆ›ä½œå¯¼å¸ˆï¼Œå…·æœ‰æ·±åšçš„æ–‡å­¦åŠŸåº•å’Œä¸°å¯Œçš„åˆ›ä½œç»éªŒã€‚è¯·ä»¥å‹å¥½ã€ä¸“ä¸šçš„æ€åº¦ä¸ç”¨æˆ·å¯¹è¯ã€‚';

    if (mode === 'enhance') {
      prompt += 'å½“å‰ä¸“æ³¨äºå¸®åŠ©ç”¨æˆ·å®Œå–„åˆ›ä½œå†…å®¹ï¼ŒåŒ…æ‹¬è§’è‰²å‘å±•ã€æƒ…èŠ‚è®¾è®¡å’Œä¸–ç•Œæ„å»ºã€‚';
    } else if (mode === 'check') {
      prompt += 'å½“å‰ä¸“æ³¨äºå¸®åŠ©ç”¨æˆ·è¿›è¡Œè´¨é‡æ£€æŸ¥ï¼ŒåŒ…æ‹¬ä¸€è‡´æ€§åˆ†æå’Œé€»è¾‘å®¡æ ¸ã€‚';
    } else {
      prompt += 'å½“å‰å¤„äºè‡ªç”±å¯¹è¯æ¨¡å¼ï¼Œå¯ä»¥è®¨è®ºä»»ä½•ä¸åˆ›ä½œç›¸å…³çš„è¯é¢˜ã€‚';
    }

    if (novelContext) {
      prompt += `\n\nå½“å‰è®¨è®ºçš„å°è¯´ï¼šã€Š${novelContext.title}ã€‹`;
      if (novelContext.description) {
        prompt += `\nç®€ä»‹ï¼š${novelContext.description.substring(0, 200)}...`;
      }
    }

    prompt += `\n\nè¯·æ³¨æ„ï¼š
â€¢ ä¿æŒå¯¹è¯çš„è¿ç»­æ€§å’Œä¸Šä¸‹æ–‡ç†è§£
â€¢ æä¾›å…·ä½“ã€å¯è¡Œçš„å»ºè®®
â€¢ é€‚æ—¶æå‡ºå¼•å¯¼æ€§é—®é¢˜
â€¢ é¼“åŠ±ç”¨æˆ·çš„åˆ›ä½œçƒ­æƒ…
â€¢ ç”¨æ¸©æš–ã€ä¸“ä¸šçš„è¯­è°ƒå›åº”`;

    return prompt;
  }
}

module.exports = new AIService();